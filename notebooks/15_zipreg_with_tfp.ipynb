{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15_zipreg_with_tfp.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J33av_vA1Y3m"
      },
      "source": [
        "# Modelling count data with Tensoflow Probability\n",
        "\n",
        "In this notebook you will work with TFP. You will set up regression models that are able to output different conditional probability distributions to model count data. You will define different models with Keras, sklearn and the Tensorflow probability framework and optimize the negative log likelihood (NLL).\n",
        "You compare the performace of the Poisson regression vs. the linear regression on a test dataset.\n",
        "\n",
        "**Dataset:** \n",
        "You work with a camper dataset form https://stats.idre.ucla.edu/r/dae/zip/. The dataset contains data on 250 groups that went to a park. Each group was questioned about how many fish they caught (count), how many children were in the group (child), how many people were in the group (persons), if they used a live bait  and whether or not they brought a camper to the park (camper).\n",
        "You split the data into train and test dataset.\n",
        "\n",
        "**Content:**\n",
        "* Work with different distributions in TFP: Normal and Poisson\n",
        "* Load and split the camper dataset \n",
        "* Fit different regression models to the camper train dataset: linar regression and Poisson regression \n",
        "* Plot the predicted probability distributions (CPD) for two specific datapoints along with their likelihood\n",
        "* Plot the testdata along with the predicted mean and the 2.5% and 97.5% percentiles of the predicted CPD\n",
        "* Compare the different models based on the test NLL \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nIHYY2rSO4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bPlT84Mqd9GZ",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow_probability==0.8.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DOhO_5Pt-N9E"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WLP-37UY1Y31",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('default')\n",
        "\n",
        "tfd = tfp.distributions\n",
        "tfb = tfp.bijectors\n",
        "print(\"TFP Version\", tfp.__version__)\n",
        "print(\"TF  Version\",tf.__version__)\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rg3ZShNd8DvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Input \n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "18dtcjMG1Y4E"
      },
      "source": [
        "### Loading real count data\n",
        "\n",
        "Here you load the camper data from: https://stats.idre.ucla.edu/r/dae/zip/. The traget variable is the number of fish caught, during a state park visit by a group. You have data of 250 groups that went to the park. Each group was questioned about how many fish they caught (count), how many children were in the group (child), how many people were in the group (persons), if they used a live bait (livebait) and whether or not they brought a camper to the park (camper). This will be the features.\n",
        "You randomly split the data into train and test dataset (80% train and 20% test)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eQuwzZUj1Y4L",
        "colab": {}
      },
      "source": [
        "# The Fish Data Set\n",
        "# See example 2 from https://stats.idre.ucla.edu/r/dae/zip/ \n",
        "#\"nofish\",\"livebait\",\"camper\",\"persons\",\"child\",\"xb\",\"zg\",\"count\"\n",
        "dat = np.loadtxt('https://raw.githubusercontent.com/tensorchiefs/dl_book/master/data/fish.csv',delimiter=',', skiprows=1)\n",
        "X = dat[...,1:5] #\"livebait\",\"camper\",\"persons\",\"child\n",
        "y = dat[...,7]\n",
        "X=np.array(X,dtype=\"float32\")\n",
        "y=np.array(y,dtype=\"float32\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ILaYEVVnBN3F"
      },
      "source": [
        "Let's split the data and look at the counts (how many fish each group caught).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RCdA9LKL1Y4Y",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,shuffle=True)\n",
        "d = X_train.shape[1]\n",
        "print(X_train.shape, y_train.shape) \n",
        "print(X_test.shape, y_test.shape) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mFv-HckTdxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y_test[0:10], y_train[0:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vTcHrKJVByqM"
      },
      "source": [
        "In the following we will look at the number of fish each group caught. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RVqCbgQZ1Y4e",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(14,5))\n",
        "\n",
        "vals, counts = np.unique(y_train, return_counts=True)\n",
        "plt.subplot(1,2,1)\n",
        "plt.stem(vals, counts,use_line_collection=True)\n",
        "plt.xlabel('Count: number of fish caught')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of number of fish caught in training')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.stem(vals, counts,use_line_collection=True)\n",
        "plt.xlabel('Count: number of fish caught')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xlim(-1,10)\n",
        "plt.title('Zoomed distribution of number of fish caught in training')\n",
        "plt.show()\n",
        "\n",
        "np.max(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fWdfVAeiPhMP"
      },
      "source": [
        "You see that most of the groups didn't catch any fish at all. Most of the groups were not very successful, but there is one group that was very successful and caught 149 fish!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T2LZ1O7SPyZe"
      },
      "source": [
        "Lets pick the two test observations 31 and 33, which you will investigate in the following. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lNnxCICNwElp",
        "colab": {}
      },
      "source": [
        "print(X_test[31])#\"livebait\",\"camper\",\"persons\",\"child\n",
        "print(X_test[33])#\"livebait\",\"camper\",\"persons\",\"child\n",
        "print(y_test[31])#\"number of caught fish\n",
        "print(y_test[33])#\"number of caught fish"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MAzV_poQQLqe"
      },
      "source": [
        "Group 31 used livebait, had a camper and were 4 persons with one child. They caught 5 fish.  \n",
        "Group 33 used livebait, didn't have a camper and were 4 persons with two childern. They caught 0 fish."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PJWH_iYP1Y7a"
      },
      "source": [
        "## Zero inflated Poisson Regression \n",
        "\n",
        "You saw that there are a lot of unlucky groups that did not catch any fish at all. You will now define a model with two outputs, one for the poisson mean and one for the probability that zero fish were caught. This is the so called zero-inflated Poisson distribution. You use the TFP framework to create a mixture two processes: a Poission process and a zero generating process. You will not use any hidden layers in between and the loss will be the NLL. After the fitting, you predict the test data and compare the performance with the other models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dWyekfiA9lxG"
      },
      "source": [
        "The ZIP distribution needs two parameters:\n",
        "* rate: which defines the rate $\\lambda$ of a Poisson process\n",
        "* s: the probability to pick Poisson process (accordingly the zero-generating process is picked with probability 1-s)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s9tYvDbj1Y7b",
        "colab": {}
      },
      "source": [
        "def zero_inf(out): \n",
        "    rate = tf.squeeze(tf.math.exp(out[:,0:1])) #A \n",
        "    s = tf.math.sigmoid(out[:,1:2]) #B  \n",
        "    probs = tf.concat([1-s, s], axis=1) #C \n",
        "    return tfd.Mixture(\n",
        "          cat=tfd.Categorical(probs=probs),#D\n",
        "          components=[\n",
        "          tfd.Deterministic(loc=tf.zeros_like(rate)), #E\n",
        "          tfd.Poisson(rate=rate), #F \n",
        "        ])\n",
        "\n",
        "#A The first component codes for the rate. We used exponential to guaranty values > 0. We also used the squeeze function to flatten the tensor.\n",
        "#B The second component codes for zero inflation; using the sigmoid squeezes the value between 0 and 1.\n",
        "#C The two probabilities for 0’s or Poissonian distribution \n",
        "#D tfd.Categorical allows creating a mixture of two components. \n",
        "#E Zero as a deterministic value \n",
        "#F Value drawn from a Poissonian distribution"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2dxIHn1UkwHp"
      },
      "source": [
        "In the next cell you can check if the ZIP distribution is working. As you can see in the code above, the zero_inf distribution takes two values as input. The first value controls the rate of the Poisson distribution and the second value controls the probability to pick the Poisson process. Both values can be negative or positive. To guarantee that the rate is a positive number, we transform the first argument with the exp() function.To guarantee that the probability s is a number between zero and one, we transform the second argument with the sigmoid() function.  \n",
        "\n",
        "If the first argument is 1 then the rate of the Poisson process is exp(1) ~ 2.7. If the second argument is 10 then the probability to pick the Poisson process is sigmoid(10) ~ 0.9999. Accordingly, if the input to the zero_inf() distribution is 1 and 10, we would expect that we almost always take the Poisson process which has a rate parameter of ~ 2.7.  \n",
        "\n",
        "If the input to the zero_inf() distribution is 1 and -10, we would expect that we almost always pick the zero-generating process. \n",
        "  \n",
        "In the following cell you can check that the zero_inf function works as expected. It is also possible to sample from the distribution or calculate the mean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0cObilkk1Y7g",
        "colab": {}
      },
      "source": [
        "## testinging the distribution, we evalute some data \n",
        "\n",
        "print(\"rate of the poissonian :\", tf.exp(1.0).numpy())\n",
        "print(\"probability to pick the poisson process :\" ,tf.math.sigmoid(10.0).numpy())\n",
        "print(\"probability to pick the poisson process :\" ,tf.math.sigmoid(-10.0).numpy())\n",
        "\n",
        "\n",
        "t = np.ones((2,2), dtype=np.float32)\n",
        "t[0,0] = 1\n",
        "t[0,1] = 10#almost always take pois \n",
        "t[1,0] = 1\n",
        "t[1,1] = -10# almost always take zero\n",
        "#t = tf.cast(t, dtype=\"float32\")\n",
        "print('Input Tensor : ')\n",
        "print(t)\n",
        "print('Output Mean  : ',zero_inf(t).mean().numpy())\n",
        "print('Output Sample  : ',zero_inf(t).sample().numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iNVLvmqF4jgL"
      },
      "source": [
        "Here you define the network and use the zero_inf distribution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IhkJUDNW1Y7m",
        "colab": {}
      },
      "source": [
        "## Definition of the custom parametrized distribution\n",
        "inputs = tf.keras.layers.Input(shape=(X_train.shape[1],))  \n",
        "out = Dense(2)(inputs) #A\n",
        "p_y_zi = tfp.layers.DistributionLambda(zero_inf)(out)\n",
        "model_zi = Model(inputs=inputs, outputs=p_y_zi)\n",
        "\n",
        "#A A dense layer is used without activation. The transformation is done inside the zero_inf function\n",
        "model_zi.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LjpdKTYq1Y7t"
      },
      "source": [
        "### Training using keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QbmF_D-p1Y7u",
        "colab": {}
      },
      "source": [
        "def NLL(y_true, y_hat):\n",
        "    return -y_hat.log_prob(tf.reshape(y_true,(-1,)))\n",
        "\n",
        "model_zi.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01), loss=NLL)\n",
        "hist_zi = model_zi.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs=2000, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BTrC-2dzW8_-",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(hist_zi.history['loss'])\n",
        "plt.plot(hist_zi.history['val_loss'])\n",
        "plt.legend(['ZI loss','ZI val_loss'])\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('NLL')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YLquO2M5Y_gX"
      },
      "source": [
        "#### Evaluation of the Performance \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dwM1es891Y74",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=inputs, outputs=p_y_zi.mean()) \n",
        "y_hat_test = model.predict(X_test).flatten()\n",
        "\n",
        "\n",
        "mse=np.sqrt(np.mean((y_test - y_hat_test)**2))\n",
        "mae=np.mean(np.abs(y_test - y_hat_test)) \n",
        "\n",
        "NLL = model_zi.evaluate(X_test, y_test) #returns the NLL \n",
        "\n",
        "\n",
        "df4 = pd.DataFrame(\n",
        "         { 'RMSE' : mse, 'MAE' : mae, 'NLL (mean)' : NLL}, index=['ZIP (TFP)']\n",
        ")\n",
        "df4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LzEnO51Pm2BI"
      },
      "source": [
        "In the pandas dataframe above you see that the RMSE, MAE and the NLL of the diferent models. You see that the ZIP regression outperforms the Poisson and the Linear regression models  because of the lower NLL."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vgdfkpZynPwm"
      },
      "source": [
        "Let's plot the observed values vs the predicted mean of caught fish on the test dataset. To inicate the CPD you also plot  the 2.5% and 97.5% percentiles of the predicted CPD. You highlight the observations 31 and 33."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3Sc175du1Y79",
        "colab": {}
      },
      "source": [
        "samples=model_zi(X_test).sample(5000).numpy()\n",
        "lower=np.quantile(samples,0.025,axis=0)\n",
        "upper=np.quantile(samples,0.975,axis=0)\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.scatter(y_hat_test, y_test, alpha=0.3)\n",
        "plt.scatter(y_hat_test[33], y_test[33],c=\"orange\",marker='o',edgecolors= \"black\")\n",
        "plt.scatter(y_hat_test[31], y_test[31],c=\"orange\",marker='o',edgecolors= \"black\")\n",
        "\n",
        "plt.title('Comparison on the testset')\n",
        "plt.xlabel('predicted average of caught fish')\n",
        "plt.ylabel('observed number of caught fish')\n",
        "plt.plot(y_hat_test[np.argsort(y_hat_test,axis=0)].flatten(), lower[np.argsort(y_hat_test,axis=0)],linestyle='dashed',c=\"black\")\n",
        "plt.plot(y_hat_test[np.argsort(y_hat_test,axis=0)].flatten(), upper[np.argsort(y_hat_test,axis=0)],linestyle='dashed',c=\"black\")\n",
        "plt.plot(y_hat_test, y_hat_test, c=\"black\")\n",
        "\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.scatter(y_hat_test, y_test, alpha=0.3)\n",
        "plt.scatter(y_hat_test[33], y_test[33],c=\"orange\",marker='o',edgecolors= \"black\")\n",
        "plt.scatter(y_hat_test[31], y_test[31],c=\"orange\",marker='o',edgecolors= \"black\")\n",
        "\n",
        "plt.title('Zoomed comparison on the testset')\n",
        "plt.xlabel('predicted average of caught fish')\n",
        "plt.ylabel('observed number of caught fish')\n",
        "plt.plot(y_hat_test[np.argsort(y_hat_test,axis=0)].flatten(), lower[np.argsort(y_hat_test,axis=0)],linestyle='dashed',c=\"black\")\n",
        "plt.plot(y_hat_test[np.argsort(y_hat_test,axis=0)].flatten(), upper[np.argsort(y_hat_test,axis=0)],linestyle='dashed',c=\"black\")\n",
        "plt.plot(y_hat_test, y_hat_test, c=\"black\")\n",
        "plt.xlim([-0.5,6])\n",
        "plt.ylim([-0.5,6])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GMCbYE29nroP"
      },
      "source": [
        "Compared to the Poisson model it is striking that the 2.5% percentile is zero over the whole range. This is due the zero-inflated process modeling a higher amount of zeros compared to the Poisson process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0PwBywhEnaEc",
        "colab": {}
      },
      "source": [
        "# Let's check the mean of the predicted CPDs for the obeservations nr 31 and 33\n",
        "print(y_hat_test[31])\n",
        "print(y_hat_test[33])\n",
        "# Remember the observed nr of caught fish for the obeservations nr 31 and 33\n",
        "print(y_test[31])\n",
        "print(y_test[33])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L-gOH43vnj1G"
      },
      "source": [
        "Lets check the predicted outcome distribution for the observations 31 and 33."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2M1VM1bnwE5j",
        "colab": {}
      },
      "source": [
        "probs=model_zi(X_test).prob(np.arange(0,20,1).reshape(20,1)).numpy()\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.stem(np.arange(0,20,1),probs[:,31],use_line_collection=True)\n",
        "plt.vlines(np.expand_dims(y_test,axis=1)[31], ymin=0, ymax=probs[np.int(y_test[31]),31],linestyle='dotted',color=\"purple\",linewidth=4)\n",
        "plt.xticks(np.arange(0,20,1))\n",
        "plt.xlabel('Number of Events')\n",
        "plt.ylabel('Probability')\n",
        "plt.title('Test observation 31, observed fish=5')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.stem(np.arange(0,20,1),probs[:,33],use_line_collection=True)\n",
        "plt.vlines(np.expand_dims(y_test,axis=1)[33], ymin=0, ymax=probs[np.int(y_test[33]),33],linestyle='dotted',color=\"purple\",linewidth=4)\n",
        "plt.xticks(np.arange(0,20,1))\n",
        "plt.xlabel('Number of Events')\n",
        "plt.ylabel('Probability')\n",
        "plt.title('Test observation 33, observed fish=0')\n",
        "plt.show()\n",
        "#plt.savefig(\"zip_dist_31_33.pdf\")\n",
        "#from google.colab import files\n",
        "#files.download('zip_dist_31_33.pdf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Cb_VU8L3oZe1"
      },
      "source": [
        "You can see that the  predicted CPDs has a large peak at zero. This is due the zero-inflated process modeling a higher amount of zeros compared to the Poisson process.  \n",
        "You can see that the liklihood of the observed values are quite high under the predicted CPDs (dotted line). Note that the ZIP CPD does only predict non-negative integer values which is a quite nice property for count data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qwxUFHulpE_l",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}